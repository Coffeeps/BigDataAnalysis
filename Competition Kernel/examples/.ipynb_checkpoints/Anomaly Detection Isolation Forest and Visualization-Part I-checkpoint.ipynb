{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原文：\n",
    "https://www.kaggle.com/adithya44/anomaly-detection-isolation-forest-visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "print(os.listdir('../input'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../input/metric_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I do a pivot on the dataframe to create a dataframe with all metrics at a date level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df=pd.pivot_table(df,values='actuals',index='load_date',columns='metric_name')\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level the multi-index pivot dataframe and treat na with 0\n",
    "metrics_df.reset_index(inplace=True)\n",
    "metrics_df.fillna(0,inplace=True)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_model_columns=metrics_df.columns[1:13]\n",
    "to_model_columns=metrics_df.columns[1:13]\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf=IsolationForest(n_estimators=100, max_samples='auto', \\\n",
    "                    max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "\n",
    "clf.fit(metrics_df[to_model_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(metrics_df[to_model_columns])\n",
    "metrics_df['anomaly']=pred\n",
    "outliers=metrics_df.loc[metrics_df['anomaly']==-1]\n",
    "outlier_index=list(outliers.index)\n",
    "# print(outlier_index)\n",
    "\n",
    "# Find the number of anomalies and normal points here points classified -1 are anomalous\n",
    "print(metrics_df['anomaly'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize and fit the metrics to a PCA to reduce the number of dimensions and then plot them in 3D highlighting the anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pca = PCA(n_components=3)  # Reduce to k=3 dimensions\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# normalize the metrics\n",
    "X = scaler.fit_transform(metrics_df[to_model_columns])\n",
    "X_reduce = pca.fit_transform(X)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_zlabel(\"x_composite_3\")\n",
    "\n",
    "# Plot the compressed data points\n",
    "ax.scatter(X_reduce[:, 0], X_reduce[:, 1], zs=X_reduce[:, 2], s=4, lw=1, label=\"inliers\", c=\"green\")\n",
    "\n",
    "# Plot x's for the ground truth outliers\n",
    "ax.scatter(X_reduce[outlier_index,0],X_reduce[outlier_index,1], X_reduce[outlier_index,2],\n",
    "           lw=2, s=60, marker=\"x\", c=\"red\", label=\"outliers\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we see the 3D point the anomaly points are mostly wide from the cluster of normal points,but a 2D point will help us to even judge better. Lets try plotting the same fed to a PCA reduced to 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(2)\n",
    "pca.fit(metrics_df[to_model_columns])\n",
    "\n",
    "\n",
    "res=pd.DataFrame(pca.transform(metrics_df[to_model_columns]))\n",
    "\n",
    "Z = np.array(res)\n",
    "figsize=(12, 7)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.title(\"IsolationForest\")\n",
    "plt.contourf( Z, cmap=plt.cm.Blues_r)\n",
    "\n",
    "b1 = plt.scatter(res[0], res[1], c='blue',\n",
    "                 s=40,label=\"normal points\")\n",
    "\n",
    "b1 = plt.scatter(res.iloc[outlier_index,0],res.iloc[outlier_index,1], c='red',\n",
    "                 s=40,  edgecolor=\"red\",label=\"predicted outliers\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the contamination parameter plays a great factor. Our idea here is to capture all the anomalous point in the system. So its better to identify few points which might be normal as anomalous(false positives) ,but not to miss out catching an anomaly(true negative).(So i have specified 12% as contamintion which varies based on use case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates actuals plot on a time series with anomaly points highlighted on it. Also a table which provides actual data, the change and conditional formatting based on anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.plotly as py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "def plot_anomaly(df,metric_name):\n",
    "    df.load_date = pd.to_datetime(df['load_date'].astype(str), format=\"%Y%m%d\")\n",
    "    dates = df.load_date\n",
    "    #identify the anomaly points and create a array of its values for plot\n",
    "    bool_array = (abs(df['anomaly']) > 0)\n",
    "    actuals = df[\"actuals\"][-len(bool_array):]\n",
    "    anomaly_points = bool_array * actuals\n",
    "    anomaly_points[anomaly_points == 0] = np.nan\n",
    "    #A dictionary for conditional format table based on anomaly\n",
    "    color_map = {0: \"'rgba(228, 222, 249, 0.65)'\", 1: \"yellow\", 2: \"red\"}\n",
    "    \n",
    "    #Table which includes Date,Actuals,Change occured from previous point\n",
    "    table = go.Table(\n",
    "        domain=dict(x=[0, 1],\n",
    "                    y=[0, 0.3]),\n",
    "        columnwidth=[1, 2],\n",
    "        # columnorder=[0, 1, 2,],\n",
    "        header=dict(height=20,\n",
    "                    values=[['<b>Date</b>'], ['<b>Actual Values </b>'], ['<b>% Change </b>'],\n",
    "                            ],\n",
    "                    font=dict(color=['rgb(45, 45, 45)'] * 5, size=14),\n",
    "                    fill=dict(color='#d562be')),\n",
    "        cells=dict(values=[df.round(3)[k].tolist() for k in ['load_date', 'actuals', 'percentage_change']],\n",
    "                   line=dict(color='#506784'),\n",
    "                   align=['center'] * 5,\n",
    "                   font=dict(color=['rgb(40, 40, 40)'] * 5, size=12),\n",
    "                   # format = [None] + [\",.4f\"] + [',.4f'],\n",
    "                   # suffix=[None] * 4,\n",
    "                   suffix=[None] + [''] + [''] + ['%'] + [''],\n",
    "                   height=27,\n",
    "                   fill=dict(color=[test_df['anomaly_class'].map(color_map)],#map based on anomaly level from dictionary\n",
    "                   )\n",
    "                   ))\n",
    "    #Plot the actuals points\n",
    "    Actuals = go.Scatter(name='Actuals',\n",
    "                         x=dates,\n",
    "                         y=df['actuals'],\n",
    "                         xaxis='x1', yaxis='y1',\n",
    "                         mode='line',\n",
    "                         marker=dict(size=12,\n",
    "                                     line=dict(width=1),\n",
    "                                     color=\"blue\"))\n",
    "\n",
    "    #Highlight the anomaly points\n",
    "    anomalies_map = go.Scatter(name=\"Anomaly\",\n",
    "                               showlegend=True,\n",
    "                               x=dates,\n",
    "                               y=anomaly_points,\n",
    "                               mode='markers',\n",
    "                               xaxis='x1',\n",
    "                               yaxis='y1',\n",
    "                               marker=dict(color=\"red\",\n",
    "                                           size=11,\n",
    "                                           line=dict(\n",
    "                                               color=\"red\",\n",
    "                                               width=2)))\n",
    "\n",
    "    axis = dict(\n",
    "        showline=True,\n",
    "        zeroline=False,\n",
    "        showgrid=True,\n",
    "        mirror=True,\n",
    "        ticklen=4,\n",
    "        gridcolor='#ffffff',\n",
    "        tickfont=dict(size=10))\n",
    "\n",
    "    layout = dict(\n",
    "        width=1000,\n",
    "        height=865,\n",
    "        autosize=False,\n",
    "        title=metric_name,\n",
    "        margin=dict(t=75),\n",
    "        showlegend=True,\n",
    "        xaxis1=dict(axis, **dict(domain=[0, 1], anchor='y1', showticklabels=True)),\n",
    "        yaxis1=dict(axis, **dict(domain=[2 * 0.21 + 0.20, 1], anchor='x1', hoverformat='.2f')))\n",
    "\n",
    "    fig = go.Figure(data=[table, anomalies_map, Actuals], layout=layout)\n",
    "\n",
    "    iplot(fig)\n",
    "    pyplot.show()\n",
    "    #return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_anomalies(df,metric_name):\n",
    "    df['metric_name']=metric_name\n",
    "    df = df.sort_values(by='load_date', ascending=False)\n",
    "    \n",
    "    # Shift actuals by one timestamp to find the percentage chage between current and previous data point\n",
    "    df['shift'] = df['actuals'].shift(-1)\n",
    "    df['percentage_change'] = ((df['actuals'] - df['shift']) / df['actuals']) * 100\n",
    "    \n",
    "    # Categorise anomalies as 0-no anomaly, 1- low anomaly , 2 - high anomaly\n",
    "    df['anomaly'].loc[df['anomaly'] == 1] = 0\n",
    "    df['anomaly'].loc[df['anomaly'] == -1] = 2\n",
    "    df['anomaly_class'] = df['anomaly']\n",
    "    max_anomaly_score = df['score'].loc[df['anomaly_class'] == 2].max()\n",
    "    medium_percentile = df['score'].quantile(0.24)\n",
    "    df['anomaly_class'].loc[(df['score'] > max_anomaly_score) & (df['score'] <= medium_percentile)] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual values of metrics are indicated in the blue line and anomaly points are highlighted as red points.\n",
    "\n",
    "In the table, background red indicates high anomalies and yellow indicates low anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_anomalies(df,metric_name):\n",
    "    df['metric_name']=metric_name\n",
    "    df = df.sort_values(by='load_date', ascending=False)\n",
    "    #Shift actuals by one timestamp to find the percentage chage between current and previous data point\n",
    "    df['shift'] = df['actuals'].shift(-1)\n",
    "    df['percentage_change'] = ((df['actuals'] - df['shift']) / df['actuals']) * 100\n",
    "    #Categorise anomalies as 0-no anomaly, 1- low anomaly , 2 - high anomaly\n",
    "    df['anomaly'].loc[df['anomaly'] == 1] = 0\n",
    "    df['anomaly'].loc[df['anomaly'] == -1] = 2\n",
    "    df['anomaly_class'] = df['anomaly']\n",
    "    max_anomaly_score = df['score'].loc[df['anomaly_class'] == 2].max()\n",
    "    medium_percentile = df['score'].quantile(0.24)\n",
    "    df['anomaly_class'].loc[(df['score'] > max_anomaly_score) & (df['score'] <= medium_percentile)] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "for i in range(1,len(metrics_df.columns)-1):\n",
    "    clf.fit(metrics_df.iloc[:,i:i+1])\n",
    "    pred = clf.predict(metrics_df.iloc[:,i:i+1])\n",
    "    test_df=pd.DataFrame()\n",
    "    test_df['load_date']=metrics_df['load_date']\n",
    "    #Find decision function to find the score and classify anomalies\n",
    "    test_df['score']=clf.decision_function(metrics_df.iloc[:,i:i+1])\n",
    "    test_df['actuals']=metrics_df.iloc[:,i:i+1]\n",
    "    test_df['anomaly']=pred\n",
    "    #Get the indexes of outliers in order to compare the metrics with use case anomalies if required\n",
    "    outliers=test_df.loc[test_df['anomaly']==-1]\n",
    "    outlier_index=list(outliers.index)\n",
    "    test_df=classify_anomalies(test_df,metrics_df.columns[i])\n",
    "    plot_anomaly(test_df,metrics_df.columns[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，条件格式表还提供了一些有关情况的见解，例如不存在的数据（值为零）被捕获为高异常，这可能是数据处理中流水线断开的潜在结果，需要修复并突出显示高低异常。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
